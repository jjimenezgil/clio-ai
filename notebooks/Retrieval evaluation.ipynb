{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517e0deb-98ad-4a93-9ca1-13d60849d91c",
   "metadata": {},
   "source": [
    "# Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd3f1027-d2af-49d2-a3be-439cfc5376d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import random\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import pickle\n",
    "import gzip\n",
    "from elasticsearch import Elasticsearch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e6d61b-7bcb-4310-b377-cc24de66a808",
   "metadata": {},
   "source": [
    "## 1 - Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81458e38-9d4a-4729-a56a-1697fe2229dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to load the data and apply all the cleaning developed in the Ingestion notebook\n",
    "def load_dataset(data_path=\"../data/ancient_sources.csv.gz\"):\n",
    "    df = pd.read_csv(data_path, compression=\"gzip\")\n",
    "\n",
    "    # Append index as ID\n",
    "    df['Id'] = df.index\n",
    "\n",
    "    # Delete rows without text\n",
    "    df.drop(df[df[\"text\"].isna()].index, inplace=True)\n",
    "    \n",
    "    # Transform rows with NaN section to \"\"\n",
    "    df['section'] = df['section'].fillna(\"\")\n",
    "\n",
    "    # Truncate longest texts\n",
    "    df[\"num_words\"] = df[\"text\"].apply(count_words)\n",
    "    df[\"text\"] = df[\"text\"].apply(truncate_texts)\n",
    "\n",
    "    # Drop number of words column\n",
    "    df.drop('num_words', axis=1, inplace=True)\n",
    "\n",
    "    # Transform into a list of dicts\n",
    "    df_dict = df.to_dict(orient=\"records\")\n",
    "\n",
    "    # Load embeddings and append to each dict\n",
    "    embeddings = load_embeddings()\n",
    "    normalized_embeddings = np.apply_along_axis(normalize_vector, 1, embeddings)\n",
    "    for i, source in enumerate(df_dict):\n",
    "        source[\"text_embedding\"] = normalized_embeddings[i]\n",
    "\n",
    "    return df_dict\n",
    "    \n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "\n",
    "def truncate_texts(text, max_num_words=512):\n",
    "    word_list = text.split()\n",
    "    if len(word_list) > max_num_words:\n",
    "        word_list = word_list[:max_num_words]\n",
    "\n",
    "    return \" \".join(word_list)\n",
    "\n",
    "\n",
    "def load_embeddings(path=\"../data/embeddings.h5\"):\n",
    "    with h5py.File(path, 'r') as hf:\n",
    "        dataset = hf['embeddings']\n",
    "        \n",
    "        # Load the data into a NumPy array\n",
    "        embeddings = dataset[:]\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "def load_title_embeddings(path=\"../data/title_embeddings.h5\"):\n",
    "    with h5py.File('../data/title_embeddings.h5', 'r') as hf:\n",
    "        dataset = hf['title_embeddings']\n",
    "    \n",
    "        # Load the data into a NumPy array\n",
    "        title_embeddings_array = dataset[:]\n",
    "        return title_embeddings_array\n",
    "\n",
    "\n",
    "def normalize_vector(vector):\n",
    "    norm = np.linalg.norm(vector)\n",
    "    if norm == 0:\n",
    "        return vector  # Avoid division by zero\n",
    "    return vector / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f226fbcb-35ae-492d-9415-4cef46d07c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_dict = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d710c767-9192-46bb-82d6-e7c4802970c1",
   "metadata": {},
   "source": [
    "## 2 - Generate ground truth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1caa496a-2b4a-474c-a9bd-f90c69d9a388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Login keys\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "298522d2-37b4-4bec-8f45-9b1cf5456b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To interact with OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "747a7736-5e63-4249-aa42-acd89a008019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a prompt asking for questions about the data\n",
    "prompt_template = \"\"\"\n",
    "You are an expert historian tasked with generating a question based on the following historical record. \n",
    "Your question should be specific and answerable using the information in the record. However, you must avoid repeating too many exact \n",
    "words from the record. Focus on key details like dates, persons, events, the author or title. Keep the question concise \n",
    "and insightful.\n",
    "\n",
    "Historical record:\n",
    "\n",
    "Author: {author}\n",
    "Title: {title}\n",
    "Text: {text}\n",
    "\n",
    "Question:\n",
    "\"\"\".strip()\n",
    "\n",
    "def generate_prompt(data, prompt_template=prompt_template):\n",
    "    return prompt_template.format(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e598f8f-d431-4b1b-999b-01ef03ec0700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107d4a1-2df2-4c4e-b38f-cbddf8ebabea",
   "metadata": {},
   "source": [
    "Let's generate 1000 questions about 1000 randomly chosen ancient sources in our list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba5a4bb3-d215-49c7-abd9-32a6d394e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only the records with a relevant text (let's say at least 20 words)\n",
    "df_dict_filtered = list(filter(lambda x: len(x[\"text\"].split()) >= 20, df_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82800181-db1d-4cae-97d2-7c6094e1b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 1000 random records\n",
    "random_elements = random.sample(df_dict_filtered, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6e0cee6-4443-461d-b24c-dabb1efb02d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ef5abac97346b8af9c115ecd23a8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ground_truth = []\n",
    "\n",
    "for elem in tqdm(random_elements):\n",
    "    prompt = generate_prompt(elem)\n",
    "    question = generate_question(prompt)\n",
    "    question_with_answer_id = {\"id\": elem[\"Id\"], \"question\": question}\n",
    "    ground_truth.append(question_with_answer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfbaea1-a4a0-4639-a14f-670ed3e29ceb",
   "metadata": {},
   "source": [
    "Let's generate another 500 questions that ask for the author and title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79535a2c-5822-42e5-9fb6-19a24567a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_author = \"\"\"\n",
    "You are a skilled history student. Your task is to create a question about the provided historical text that \n",
    "focuses on identifying the authors and titles that discuss the events and persons mentioned in the text. Your question \n",
    "should encourage an in-depth search for relevant historical references, avoiding direct reuse of the text's wording.\n",
    "\n",
    "Historical text: {text}\n",
    "\n",
    "Question:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "986de672-1ac4-4db9-8603-8f3cc37ece65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 500 random records\n",
    "random_elements = random.sample(df_dict_filtered, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c724f0f4-f7e2-460d-8a51-c4ca3e8d2217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83d014716e44627b4bd58d299ac42f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for elem in tqdm(random_elements):\n",
    "    prompt = generate_prompt(elem, prompt_template=prompt_template_author)\n",
    "    question = generate_question(prompt)\n",
    "    question_with_answer_id = {\"id\": elem[\"Id\"], \"question\": question}\n",
    "    ground_truth.append(question_with_answer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a139f90e-c379-48cf-ae7a-17854d8c335f",
   "metadata": {},
   "source": [
    "And finally another 500 more generic questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b12562-3a82-4ec3-9af0-172a7a89a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_generic = \"\"\"\n",
    "Imagine you are a history student who is just starting to learn about ancient texts. Your task is to create a straightforward question \n",
    "based on the provided historical text. The question should be simple and directly answerable using the information given in the text and its title.\n",
    "\n",
    "Title: {title}\n",
    "Text: {text}\n",
    "\n",
    "Question:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e967544-5a6f-4dfb-b7e7-a411e49b4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 500 random records\n",
    "random_elements = random.sample(df_dict_filtered, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0e2c5e9-6232-4b45-95da-fb0a55a61f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48fa487b7304fbea4868c5b88d072b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for elem in tqdm(random_elements):\n",
    "    prompt = generate_prompt(elem, prompt_template=prompt_template_generic)\n",
    "    question = generate_question(prompt)\n",
    "    question_with_answer_id = {\"id\": elem[\"Id\"], \"question\": question}\n",
    "    ground_truth.append(question_with_answer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b822e5-efd0-493f-9749-84e8aa3c7d6d",
   "metadata": {},
   "source": [
    "Finally, let's add another 1000 questions with a different prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591eea34-5975-4265-918c-6731691c7327",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_mine = \"\"\"\n",
    "\n",
    "Title: {title}\n",
    "Text: {text}\n",
    "\n",
    "Question:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e1141a6-057c-49e6-8043-863be4fd456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the list in place\n",
    "random.shuffle(ground_truth)\n",
    "\n",
    "# Save the ground_truth_dataset\n",
    "with gzip.open('../data/ground_truth.pkl.gz', 'wb') as f:\n",
    "    pickle.dump(ground_truth, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419f613e-9b95-4249-820f-ba5c02598d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data back\n",
    "with gzip.open('../data/ground_truth.pkl.gz', 'rb') as f:\n",
    "    ground_truth = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca12dc5-e133-458b-a60b-3e9149783de3",
   "metadata": {},
   "source": [
    "## 3 - Rewrite search functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edca6319-4592-4d5a-b3f9-b89bac30b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic client\n",
    "es_client = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "# The index should be already created and the info indexed in the container\n",
    "index_name = \"ancient_sources_db_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b4de1ee-3a66-4d1c-9936-e1de11b74a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5abb4ae7204acfa875cc44b487596d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f32a687e4294b93925ede6e520b1297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dbb20aacdb64d8e9286f965eeeb48df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e3e36529f442078fb749edb2a0f31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235d381cf2f244fd8f7d848c0022e671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/787 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b436d95d702c4d31852f9731642b9ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21d229a730b4c0eaedd320f1e20d8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22105897e5a44469972bf5075086034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8ff282f3504c26b1dd16d1374a061b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e568fac888b1477399f5ed56e0360e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b016ea99b4845579258160db4f862f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b122961515d43aa8539bf6b54721fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fe92b66e5347bc8427be2db6182d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4efe290efc4c83a5896387569d912e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16436fb37c8643b187d8a5550e03b6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726000db4dbf41d5a01030311ff3c5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3_LayerNorm/config.json:   0%|          | 0.00/22.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7903b67f6c4b909bfd38fa8467674f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3_LayerNorm/model.safetensors:   0%|          | 0.00/6.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb5b012e46f4aeeb3ab7aa16ad8a02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/7.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the msmarco-roberta-base-ance-firstp for the query embeddings\n",
    "model = SentenceTransformer('msmarco-roberta-base-ance-firstp')\n",
    "\n",
    "# The vectors have to be normalized in order to use dot product similarity in elasticsearch\n",
    "def normalize_vector(vector):\n",
    "    norm = np.linalg.norm(vector)\n",
    "    if norm == 0:\n",
    "        return vector  # Avoid division by zero\n",
    "    return vector / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90cfdf4b-50db-4865-8fb3-2523f9cf9bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_search(query, num_results=5, boost=0.5, num_candidates=1000):\n",
    "    q_embedding = model.encode(query)\n",
    "    q_emb_normalized = normalize_vector(q_embedding)\n",
    "\n",
    "    # Vector search query\n",
    "    knn_query = {\n",
    "        \"field\": \"text_embedding\",\n",
    "        \"query_vector\": q_emb_normalized,\n",
    "        \"k\": num_results,\n",
    "        \"num_candidates\": num_candidates,\n",
    "        \"boost\": boost,\n",
    "    }\n",
    "    \n",
    "    # Semantic search query\n",
    "    keyword_query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"author\", \"title\", \"text\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                    \"boost\": boost,\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(\n",
    "        index=index_name,\n",
    "        query=keyword_query,\n",
    "        knn=knn_query,\n",
    "        size=num_results,\n",
    "        _source={\n",
    "            \"excludes\": [\"text_embedding\"]  # Exclude the embedding vectors of the response\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return response[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a67efb-8d7d-4cf2-aa3c-cda74091859b",
   "metadata": {},
   "source": [
    "## 4 - Hit Rate (HR) and Mean Reciprocal Rank (MRR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe025e-2f32-4edc-b50d-d93967aaf592",
   "metadata": {},
   "source": [
    "The initial computed HR and MRR (without any tunning) were:\n",
    "- **HR = 0.5295**\n",
    "- **MRR = 0.4226**\n",
    "\n",
    "Let's see if these metrics can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e15ca630-92a6-496e-9d89-08874ea874e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed47f69b54a4aaba46053cf3fb8fd4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevance_total = []\n",
    "\n",
    "for query in tqdm(ground_truth):\n",
    "    results = es_search(query[\"question\"])\n",
    "    relevance = [query[\"id\"]==r[\"_source\"][\"Id\"] for r in results]\n",
    "    relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d93590ad-b431-4e1c-8f11-ce08fa0d4217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    count = 0\n",
    "    \n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            count = count + 1\n",
    "\n",
    "    hr = count / len(relevance_total)\n",
    "    return hr\n",
    "\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "    \n",
    "    for line in relevance_total:\n",
    "        for i in range(len(line)):\n",
    "            if line[i] == True:\n",
    "                total_score = total_score + 1/(i+1)\n",
    "\n",
    "    mrr = total_score / len(relevance_total)\n",
    "    return mrr    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab7887d2-5619-4f18-8c81-6de7fe782aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = hit_rate(relevance_total)\n",
    "mrr = mrr(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d56f84cf-e6d9-4469-9f1d-f23ccd5547f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit-rate: 0.5295\n",
      "MRR: 0.4226333333333342\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hit-rate: {hr}\")\n",
    "print(f\"MRR: {mrr}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
