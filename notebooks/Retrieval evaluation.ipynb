{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517e0deb-98ad-4a93-9ca1-13d60849d91c",
   "metadata": {},
   "source": [
    "# Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd3f1027-d2af-49d2-a3be-439cfc5376d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# import torch\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "#from huggingface_hub import login\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import random\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e6d61b-7bcb-4310-b377-cc24de66a808",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81458e38-9d4a-4729-a56a-1697fe2229dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to load the data and apply all the cleaning developed in the Ingestion notebook\n",
    "def load_dataset(data_path=\"../data/ancient_sources.csv.gz\"):\n",
    "    df = pd.read_csv(data_path, compression=\"gzip\")\n",
    "\n",
    "    # Append index as ID\n",
    "    df['Id'] = df.index\n",
    "\n",
    "    # Delete rows without text\n",
    "    df.drop(df[df[\"text\"].isna()].index, inplace=True)\n",
    "    \n",
    "    # Transform rows with NaN section to \"\"\n",
    "    df['section'] = df['section'].fillna(\"\")\n",
    "\n",
    "    # Truncate longest texts\n",
    "    df[\"num_words\"] = df[\"text\"].apply(count_words)\n",
    "    df[\"text\"] = df[\"text\"].apply(truncate_texts)\n",
    "\n",
    "    # Drop number of words column\n",
    "    df.drop('num_words', axis=1, inplace=True)\n",
    "\n",
    "    # Transform into a list of dicts\n",
    "    df_dict = df.to_dict(orient=\"records\")\n",
    "\n",
    "    # Load embeddings and append to each dict\n",
    "    embeddings = load_embeddings()\n",
    "    normalized_embeddings = np.apply_along_axis(normalize_vector, 1, embeddings)\n",
    "    for i, source in enumerate(df_dict):\n",
    "        source[\"text_embedding\"] = normalized_embeddings[i]\n",
    "\n",
    "    return df_dict\n",
    "    \n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "\n",
    "def truncate_texts(text, max_num_words=512):\n",
    "    word_list = text.split()\n",
    "    if len(word_list) > max_num_words:\n",
    "        word_list = word_list[:max_num_words]\n",
    "\n",
    "    return \" \".join(word_list)\n",
    "\n",
    "\n",
    "def load_embeddings(path=\"../data/embeddings.h5\"):\n",
    "    with h5py.File(path, 'r') as hf:\n",
    "        dataset = hf['embeddings']\n",
    "        \n",
    "        # Load the data into a NumPy array\n",
    "        embeddings = dataset[:]\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "def normalize_vector(vector):\n",
    "    norm = np.linalg.norm(vector)\n",
    "    if norm == 0:\n",
    "        return vector  # Avoid division by zero\n",
    "    return vector / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f226fbcb-35ae-492d-9415-4cef46d07c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_dict = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d710c767-9192-46bb-82d6-e7c4802970c1",
   "metadata": {},
   "source": [
    "## Generate ground truth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1caa496a-2b4a-474c-a9bd-f90c69d9a388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Login keys\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "298522d2-37b4-4bec-8f45-9b1cf5456b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To interact with OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "747a7736-5e63-4249-aa42-acd89a008019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a prompt asking for questions about the data\n",
    "prompt_template = \"\"\"\n",
    "You are an expert historian tasked with generating a question based on the following historical record. \n",
    "Your question should be specific and answerable using the information in the record. However, you must avoid repeating too many exact \n",
    "words from the record. Focus on key details like dates, persons, events, the author or title. Keep the question concise \n",
    "and insightful.\n",
    "\n",
    "Historical record:\n",
    "\n",
    "Author: {author}\n",
    "Title: {title}\n",
    "Text: {text}\n",
    "\n",
    "Question:\n",
    "\"\"\".strip()\n",
    "\n",
    "def generate_prompt(data, prompt_template=prompt_template):\n",
    "    return prompt_template.format(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e598f8f-d431-4b1b-999b-01ef03ec0700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107d4a1-2df2-4c4e-b38f-cbddf8ebabea",
   "metadata": {},
   "source": [
    "Let's generate 1000 questions about 1000 randomly chosen ancient sources in our list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a4bb3-d215-49c7-abd9-32a6d394e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only the records with a relevant text (let's say at least 20 words)\n",
    "df_dict_filtered = list(filter(lambda x: len(x[\"text\"].split()) >= 20, df_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82800181-db1d-4cae-97d2-7c6094e1b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 1000 random records\n",
    "random_elements = random.sample(df_dict_filtered, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6e0cee6-4443-461d-b24c-dabb1efb02d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ef5abac97346b8af9c115ecd23a8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ground_truth = []\n",
    "\n",
    "for elem in tqdm(random_elements):\n",
    "    prompt = generate_prompt(elem)\n",
    "    question = generate_question(prompt)\n",
    "    question_with_answer_id = {\"id\": elem[\"Id\"], \"question\": question}\n",
    "    ground_truth.append(question_with_answer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfbaea1-a4a0-4639-a14f-670ed3e29ceb",
   "metadata": {},
   "source": [
    "Let's generate another 500 questions that ask for the author and title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79535a2c-5822-42e5-9fb6-19a24567a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_author = \"\"\"\n",
    "You are a skilled history student. Your task is to create a question about the provided historical text that \n",
    "focuses on identifying the authors and titles that discuss the events and persons mentioned in the text. Your question \n",
    "should encourage an in-depth search for relevant historical references, avoiding direct reuse of the text's wording.\n",
    "\n",
    "Historical text: {text}\n",
    "\n",
    "Question:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "986de672-1ac4-4db9-8603-8f3cc37ece65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 500 random records\n",
    "random_elements = random.sample(df_dict_filtered, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c724f0f4-f7e2-460d-8a51-c4ca3e8d2217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83d014716e44627b4bd58d299ac42f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for elem in tqdm(random_elements):\n",
    "    prompt = generate_prompt(elem, prompt_template=prompt_template_author)\n",
    "    question = generate_question(prompt)\n",
    "    question_with_answer_id = {\"id\": elem[\"Id\"], \"question\": question}\n",
    "    ground_truth.append(question_with_answer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a139f90e-c379-48cf-ae7a-17854d8c335f",
   "metadata": {},
   "source": [
    "And finally another 500 more generic questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e2aa274-3155-4a0e-bc28-f1389ac007a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_generic = \"\"\"\n",
    "Imagine you are a history student who is just starting to learn about ancient texts. Your task is to create a straightforward question \n",
    "based on the provided historical text. The question should be simple and directly answerable using the information given in the text and its title.\n",
    "\n",
    "Title: {title}\n",
    "Text: {text}\n",
    "\n",
    "Question:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e967544-5a6f-4dfb-b7e7-a411e49b4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 500 random records\n",
    "random_elements = random.sample(df_dict_filtered, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0e2c5e9-6232-4b45-95da-fb0a55a61f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48fa487b7304fbea4868c5b88d072b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for elem in tqdm(random_elements):\n",
    "    prompt = generate_prompt(elem, prompt_template=prompt_template_generic)\n",
    "    question = generate_question(prompt)\n",
    "    question_with_answer_id = {\"id\": elem[\"Id\"], \"question\": question}\n",
    "    ground_truth.append(question_with_answer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e1141a6-057c-49e6-8043-863be4fd456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the list in place\n",
    "random.shuffle(ground_truth)\n",
    "\n",
    "# Save the ground_truth_dataset\n",
    "with gzip.open('../data/ground_truth.pkl.gz', 'wb') as f:\n",
    "    pickle.dump(ground_truth, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
