{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "517e0deb-98ad-4a93-9ca1-13d60849d91c",
   "metadata": {},
   "source": [
    "# Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd3f1027-d2af-49d2-a3be-439cfc5376d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# import torch\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "#from huggingface_hub import login\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import random\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e6d61b-7bcb-4310-b377-cc24de66a808",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81458e38-9d4a-4729-a56a-1697fe2229dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to load the data and apply all the cleaning developed in the Ingestion notebook\n",
    "def load_dataset(data_path=\"../data/ancient_sources.csv.gz\"):\n",
    "    df = pd.read_csv(data_path, compression=\"gzip\")\n",
    "\n",
    "    # Append index as ID\n",
    "    df['Id'] = df.index\n",
    "\n",
    "    # Delete rows without text\n",
    "    df.drop(df[df[\"text\"].isna()].index, inplace=True)\n",
    "    \n",
    "    # Transform rows with NaN section to \"\"\n",
    "    df['section'] = df['section'].fillna(\"\")\n",
    "\n",
    "    # Truncate longest texts\n",
    "    df[\"num_words\"] = df[\"text\"].apply(count_words)\n",
    "    df[\"text\"] = df[\"text\"].apply(truncate_texts)\n",
    "\n",
    "    # Drop number of words column\n",
    "    df.drop('num_words', axis=1, inplace=True)\n",
    "\n",
    "    # Transform into a list of dicts\n",
    "    df_dict = df.to_dict(orient=\"records\")\n",
    "\n",
    "    # Load embeddings and append to each dict\n",
    "    embeddings = load_embeddings()\n",
    "    normalized_embeddings = np.apply_along_axis(normalize_vector, 1, embeddings)\n",
    "    for i, source in enumerate(df_dict):\n",
    "        source[\"text_embedding\"] = normalized_embeddings[i]\n",
    "\n",
    "    return df_dict\n",
    "    \n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "\n",
    "def truncate_texts(text, max_num_words=512):\n",
    "    word_list = text.split()\n",
    "    if len(word_list) > max_num_words:\n",
    "        word_list = word_list[:max_num_words]\n",
    "\n",
    "    return \" \".join(word_list)\n",
    "\n",
    "\n",
    "def load_embeddings(path=\"../data/embeddings.h5\"):\n",
    "    with h5py.File(path, 'r') as hf:\n",
    "        dataset = hf['embeddings']\n",
    "        \n",
    "        # Load the data into a NumPy array\n",
    "        embeddings = dataset[:]\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "def normalize_vector(vector):\n",
    "    norm = np.linalg.norm(vector)\n",
    "    if norm == 0:\n",
    "        return vector  # Avoid division by zero\n",
    "    return vector / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f226fbcb-35ae-492d-9415-4cef46d07c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_dict = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d710c767-9192-46bb-82d6-e7c4802970c1",
   "metadata": {},
   "source": [
    "## Generate ground truth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1caa496a-2b4a-474c-a9bd-f90c69d9a388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Login keys\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "298522d2-37b4-4bec-8f45-9b1cf5456b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To interact with OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "747a7736-5e63-4249-aa42-acd89a008019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a prompt asking for questions about the data\n",
    "prompt_template = \"\"\"\n",
    "You are an expert historian tasked with generating a question based on the following historical record. \n",
    "Your question should be specific and answerable using the information in the record. However, you must avoid repeating too many exact \n",
    "words from the record. Focus on key details like dates, persons, events, the author or title. Keep the question concise \n",
    "and insightful.\n",
    "\n",
    "Historical record:\n",
    "\n",
    "Author: {author}\n",
    "Title: {title}\n",
    "Text: {text}\n",
    "\n",
    "Question:\n",
    "\"\"\".strip()\n",
    "\n",
    "def generate_prompt(data, prompt_template=prompt_template):\n",
    "    return prompt_template.format(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e598f8f-d431-4b1b-999b-01ef03ec0700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question(source):\n",
    "    prompt = generate_prompt(source)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107d4a1-2df2-4c4e-b38f-cbddf8ebabea",
   "metadata": {},
   "source": [
    "Let's generate 500 questions about 500 randomly chosen ancient sources in our list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82800181-db1d-4cae-97d2-7c6094e1b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "random_elements = random.sample(df_dict, 500)\n",
    "\n",
    "for elem in tqdm(random_elements):\n",
    "    question = generate_question(elem)\n",
    "    question_with_answer_id = {\"id\": elem[\"id\"], \"question\": question}\n",
    "    ground_truth.append(question_with_answer_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
